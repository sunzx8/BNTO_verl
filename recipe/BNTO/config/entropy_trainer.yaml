hydra:
  searchpath:
    - file://verl/trainer/config

defaults:
  - ppo_trainer
  - _self_

data:
  gen_batch_size: ${data.train_batch_size}

reward_model:
  reward_kwargs:
        overlong_buffer_cfg: ${reward_model.overlong_buffer}
  reward_manager: dapo
  overlong_buffer: 
    enable: False 
    len: 0
    penalty_factor: 0.0
    log: False

algorithm:
  filter_groups:
    enable: False # We try to avoid forgetting to set enable
    metric: null # acc / score / seq_reward / seq_final_reward / ...
    max_num_gen_batches: 0 # Non-positive values mean no upper limit

trainer:
  project_name: verl-entropy

actor_rollout_ref:
  actor:
    policy_loss:
      loss_mode: "dual_game" # /clip-cov / kl-cov from https://arxiv.org/abs/2505.
      clip_cov_ratio: 0.0002 # for clip-cov loss
      clip_cov_lb: 1.0 # for clip-cov loss
      clip_cov_ub: 5.0 # for clip-cov loss
      kl_cov_ratio: 0.0002 # for kl-cov loss
      ppo_kl_coef: 0.1 # for kl-cov loss
      # Dual-game specific parameters
      dual_game:
        gamma: 0.8 # Negative advantage amplification factor (γ in paper)
        lambda_coef: 0.0 # λ initial value
        beta_coef: 0.0 # β initial value

# Entropy budget control configuration
entropy_budget:
  target: 0.05 # Per-token entropy budget B_t (based on theoretical analysis: w_t*H_t ≈ 0.051)
  lambda_init: 0.0 # Initial lambda coefficient
  lambda_lr: 0.1 # Learning rate for lambda updates (alpha_lambda) - increased from 0.05
  alpha: 0.001 # Decay rate parameter for entropy budget
  # Adaptive B_t parameters
  adaptive_enabled: true # Enable adaptive per-token budget calculation
  adaptive_window: 10 # Window size for adaptive B_t calculation (average of last N steps)


# Critic KL control configuration
critic:
  kl_ctrl:
    type: linear # KL control type
    kl_coef: 0.0 # Initial KL coefficient
    target_kl: 0.001 # Target KL divergence
    beta_lr: 0.001 # β learning rate
    # Adaptive target KL parameters
    adaptive_enabled: true # Enable adaptive target KL calculation
    adaptive_window: 10 # Window size for adaptive target KL calculation (average of last N steps)